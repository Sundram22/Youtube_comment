{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9nevNmkWwg_M"
   },
   "source": [
    "## Data loading\n",
    "\n",
    "### Subtask:\n",
    "Load the Youtube Comments dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "U5qkROoSwiH6",
    "outputId": "162e4c6a-6584-4076-8a43-cb9eee2825d8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lets not forget that apple pay in 2014 require...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>here in nz 50 of retailers don’t even have con...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i will forever acknowledge this channel with t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>whenever i go to a place that doesn’t take app...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apple pay is so convenient secure and easy to ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment Sentiment\n",
       "0  lets not forget that apple pay in 2014 require...   neutral\n",
       "1  here in nz 50 of retailers don’t even have con...  negative\n",
       "2  i will forever acknowledge this channel with t...  positive\n",
       "3  whenever i go to a place that doesn’t take app...  negative\n",
       "4  apple pay is so convenient secure and easy to ...  positive"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18408, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv('YoutubeCommentsDataSet.csv')\n",
    "    display(df.head())\n",
    "    print(df.shape)\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'YoutubeCommentsDataSet.csv' not found. Please ensure the file exists in the current directory.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "koIoKcbJwmz4"
   },
   "source": [
    "## Data exploration\n",
    "\n",
    "### Subtask:\n",
    "Explore the loaded dataset to understand its characteristics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bugnbisJwnDu"
   },
   "source": [
    "**Reasoning**:\n",
    "Examine data types, descriptive statistics, missing values, unique values, duplicates, and the shape of the DataFrame.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PBbPpKXswnTm",
    "outputId": "1cf5bb04-3ffc-40eb-cd34-ffb5e0d1a134"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Types:\n",
      " Comment      object\n",
      "Sentiment    object\n",
      "dtype: object\n",
      "\n",
      "Descriptive Statistics:\n",
      "                                                   Comment Sentiment\n",
      "count                                               18364     18408\n",
      "unique                                              17871         3\n",
      "top     one of the best thing about dude is that he ne...  positive\n",
      "freq                                                   10     11432\n",
      "\n",
      "Missing Values:\n",
      " Comment      44\n",
      "Sentiment     0\n",
      "dtype: int64\n",
      "\n",
      "Unique values in 'Comment':\n",
      "['lets not forget that apple pay in 2014 required a brand new iphone in order to use it a significant portion of apples user base wasnt able to use it even if they wanted to as each successive iphone incorporated the technology and older iphones were replaced the number of people who could use the technology increased'\n",
      " 'here in nz 50 of retailers don’t even have contactless credit card machines like paywave which support apple pay they don’t like the high fees that come with these'\n",
      " 'i will forever acknowledge this channel with the help of your lessons and ideas explanations now its quite helpful while youll just sit at your comfort and monitor your account growth'\n",
      " ...\n",
      " 'excelente video con una pregunta filosófica profunda gracias por compartir esta reflexión sobre la base de tu experiencia pregunta cuáles son las tres herramientas framework data base and code writing de las que hablaste en el vídeo que tú usas'\n",
      " 'hey daniel just discovered your channel a couple days ago and im learning lots thank you'\n",
      " 'this is great focus is key a playful approach can also speed things up depending on how you learn and of course patience for those interested in r and python the latest r studio ide is great and allows you to run both side by side with reticulate it can seem a steep curve but those with a grounding in r and statistics you can run ml scripts side by side and learn the similarities and where they differ']\n",
      "String length distribution in 'Comment':\n",
      "count    18408.000000\n",
      "mean       177.136897\n",
      "std        250.894504\n",
      "min          2.000000\n",
      "25%         66.000000\n",
      "50%        113.000000\n",
      "75%        201.000000\n",
      "max       7847.000000\n",
      "Name: Comment, dtype: float64\n",
      "\n",
      "Unique values in 'Sentiment':\n",
      "['neutral' 'negative' 'positive']\n",
      "String length distribution in 'Sentiment':\n",
      "count    18408.000000\n",
      "mean         7.748044\n",
      "std          0.434148\n",
      "min          7.000000\n",
      "25%          7.000000\n",
      "50%          8.000000\n",
      "75%          8.000000\n",
      "max          8.000000\n",
      "Name: Sentiment, dtype: float64\n",
      "\n",
      "Number of duplicate rows: 531\n",
      "\n",
      "Duplicate Rows:\n",
      "                                                  Comment Sentiment\n",
      "173    from all the stuff mentioned i have the dji mi...  positive\n",
      "518    happy independence day to ukraine and glory  t...  negative\n",
      "847    linus just turn the key lights 180 and bounce ...  positive\n",
      "848    dan continues to be my new favorite he has suc...  positive\n",
      "849    dan managing to set up his soldering station o...  positive\n",
      "...                                                  ...       ...\n",
      "18145  explore our free courses with completion certi...   neutral\n",
      "18283  thanks for this video very neatly calmly expla...  positive\n",
      "18298  explore our free courses with completion certi...   neutral\n",
      "18308  do you want to learn technology from me check ...   neutral\n",
      "18348  do you want to learn technology from me check ...   neutral\n",
      "\n",
      "[531 rows x 2 columns]\n",
      "\n",
      "Shape of the DataFrame:\n",
      " (18408, 2)\n"
     ]
    }
   ],
   "source": [
    "# Examine data types\n",
    "print(\"Data Types:\\n\", df.dtypes)\n",
    "\n",
    "# Descriptive statistics for numerical columns (if any)\n",
    "print(\"\\nDescriptive Statistics:\\n\", df.describe(include='all'))\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing Values:\\n\", df.isnull().sum())\n",
    "\n",
    "# Examine unique values and string length distribution\n",
    "for col in df.columns:\n",
    "    print(f\"\\nUnique values in '{col}':\")\n",
    "    print(df[col].unique())\n",
    "    if df[col].dtype == 'object':  # Check for string columns\n",
    "        print(f\"String length distribution in '{col}':\")\n",
    "        print(df[col].astype(str).str.len().describe())\n",
    "\n",
    "\n",
    "# Check for duplicate rows\n",
    "duplicate_rows = df[df.duplicated()]\n",
    "print(f\"\\nNumber of duplicate rows: {len(duplicate_rows)}\")\n",
    "print(\"\\nDuplicate Rows:\\n\", duplicate_rows)\n",
    "\n",
    "# Print the shape of the dataframe\n",
    "print(\"\\nShape of the DataFrame:\\n\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WWETB2AFwsDc"
   },
   "source": [
    "## Data cleaning\n",
    "\n",
    "### Subtask:\n",
    "Clean the data by handling missing values, removing duplicates, and addressing inconsistencies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WYKEpjXYwsTT"
   },
   "source": [
    "**Reasoning**:\n",
    "Handle missing values in the 'Comment' column by replacing them with empty strings. Remove duplicate rows. Standardize the 'Sentiment' column to lowercase.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "id": "Ph7canRlwsjI",
    "outputId": "c1a709e5-31e6-43f6-b7d0-f7113d679e9b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lets not forget that apple pay in 2014 require...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>here in nz 50 of retailers don’t even have con...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i will forever acknowledge this channel with t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>whenever i go to a place that doesn’t take app...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apple pay is so convenient secure and easy to ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment Sentiment\n",
       "0  lets not forget that apple pay in 2014 require...   neutral\n",
       "1  here in nz 50 of retailers don’t even have con...  negative\n",
       "2  i will forever acknowledge this channel with t...  positive\n",
       "3  whenever i go to a place that doesn’t take app...  negative\n",
       "4  apple pay is so convenient secure and easy to ...  positive"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17877, 2)\n"
     ]
    }
   ],
   "source": [
    "# Fill missing 'Comment' values with empty strings\n",
    "df['Comment'].fillna('', inplace=True)\n",
    "\n",
    "# Remove duplicate rows\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Standardize 'Sentiment' to lowercase\n",
    "df['Sentiment'] = df['Sentiment'].str.lower()\n",
    "\n",
    "display(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nzkqMdu7wuYu"
   },
   "source": [
    "**Reasoning**:\n",
    "The previous code block had a warning about chained assignment.  I will rewrite the code to avoid this warning and verify the data cleaning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "id": "Tb2CSXoawuo8",
    "outputId": "6c4e3a77-86e0-46fb-aafe-85082601a7be"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lets not forget that apple pay in 2014 require...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>here in nz 50 of retailers don’t even have con...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i will forever acknowledge this channel with t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>whenever i go to a place that doesn’t take app...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apple pay is so convenient secure and easy to ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment Sentiment\n",
       "0  lets not forget that apple pay in 2014 require...   neutral\n",
       "1  here in nz 50 of retailers don’t even have con...  negative\n",
       "2  i will forever acknowledge this channel with t...  positive\n",
       "3  whenever i go to a place that doesn’t take app...  negative\n",
       "4  apple pay is so convenient secure and easy to ...  positive"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17877, 2)\n",
      "\n",
      "Missing Values:\n",
      " Comment      0\n",
      "Sentiment    0\n",
      "dtype: int64\n",
      "\n",
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Fill missing 'Comment' values with empty strings\n",
    "df['Comment'] = df['Comment'].fillna('')\n",
    "\n",
    "# Remove duplicate rows\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Standardize 'Sentiment' to lowercase\n",
    "df['Sentiment'] = df['Sentiment'].str.lower()\n",
    "\n",
    "display(df.head())\n",
    "print(df.shape)\n",
    "\n",
    "# Check for missing values again\n",
    "print(\"\\nMissing Values:\\n\", df.isnull().sum())\n",
    "\n",
    "# Check for duplicates again\n",
    "duplicate_rows = df[df.duplicated()]\n",
    "print(f\"\\nNumber of duplicate rows: {len(duplicate_rows)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5HkvHBcHwyek"
   },
   "source": [
    "## Data preparation\n",
    "\n",
    "### Subtask:\n",
    "Prepare the cleaned data for further analysis or modeling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WaLHZchswzXW"
   },
   "source": [
    "**Reasoning**:\n",
    "Prepare the cleaned data for further analysis or modeling by converting the 'Sentiment' column to numerical values using Label Encoding, as it's a categorical feature, and then summarize the data preparation steps. No further feature engineering is needed at this stage.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "id": "hvjxy7A_wznI",
    "outputId": "471f4f34-e3d6-4c34-df65-0ab56a4b0912"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lets not forget that apple pay in 2014 require...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>here in nz 50 of retailers don’t even have con...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i will forever acknowledge this channel with t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>whenever i go to a place that doesn’t take app...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apple pay is so convenient secure and easy to ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  Sentiment\n",
       "0  lets not forget that apple pay in 2014 require...          1\n",
       "1  here in nz 50 of retailers don’t even have con...          0\n",
       "2  i will forever acknowledge this channel with t...          2\n",
       "3  whenever i go to a place that doesn’t take app...          0\n",
       "4  apple pay is so convenient secure and easy to ...          2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Preparation Summary:\n",
      "1. Label Encoding: The 'Sentiment' column, which is categorical, was converted into numerical representations using LabelEncoder. This is necessary for most machine learning algorithms that require numerical input.\n",
      "    - 'negative' was encoded to 0\n",
      "    - 'neutral' was encoded to 1\n",
      "    - 'positive' was encoded to 2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the 'Sentiment' column\n",
    "df['Sentiment'] = label_encoder.fit_transform(df['Sentiment'])\n",
    "\n",
    "# Display the first few rows of the DataFrame to show the changes\n",
    "display(df.head())\n",
    "\n",
    "# Summarize the data preparation steps\n",
    "print(\"\\nData Preparation Summary:\")\n",
    "print(\"1. Label Encoding: The 'Sentiment' column, which is categorical, was converted into numerical representations using LabelEncoder. This is necessary for most machine learning algorithms that require numerical input.\")\n",
    "print(\"    - 'negative' was encoded to 0\")\n",
    "print(\"    - 'neutral' was encoded to 1\")\n",
    "print(\"    - 'positive' was encoded to 2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rr7uGQaYw4rD"
   },
   "source": [
    "## Summary:\n",
    "\n",
    "### 1. Q&A\n",
    "\n",
    "No questions were explicitly asked in the provided text. However, the overall task implied a desire to understand and prepare the Youtube Comments dataset for analysis or modeling.\n",
    "\n",
    "### 2. Data Analysis Key Findings\n",
    "\n",
    "* **Missing Data:** 44 missing comments were initially present and filled with empty strings.  After cleaning, no missing values remained.\n",
    "* **Duplicate Data:** 531 duplicate rows were identified and removed. After cleaning, no duplicate rows remained.\n",
    "* **Sentiment Distribution:** The dataset contains comments labeled with three sentiments: 'negative', 'neutral', and 'positive'. The most frequent sentiment is \"positive\".\n",
    "* **Comment Length:** Comment lengths vary significantly, ranging from 2 to 7,847 characters, with an average of 177 characters.\n",
    "* **Label Encoding:** The 'Sentiment' column was successfully converted from categorical labels ('negative', 'neutral', 'positive') to numerical representations (0, 1, 2 respectively) using Label Encoding.  This is essential for using the data in machine learning models.\n",
    "* **Dataframe Shape After Cleaning:** The cleaned dataframe contains 17,877 rows and 2 columns.\n",
    "\n",
    "### 3. Insights or Next Steps\n",
    "\n",
    "* **Exploratory Data Analysis (EDA):** Conduct more in-depth EDA on the cleaned data. This could involve visualizing the distribution of sentiments, exploring relationships between comment length and sentiment, and performing word frequency analysis on the comments.\n",
    "* **Model Training:** Apply machine learning models (e.g., text classification models) to the prepared data to predict sentiment based on comment text.  This could involve splitting the data into training and testing sets, and evaluating model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "a0mM12BU0Htt"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "F7tzrJBS0hJQ"
   },
   "outputs": [],
   "source": [
    "# 1. Prepare Data:\n",
    "X = df['Comment']  # Features (comments)\n",
    "y = df['Sentiment']  # Target (sentiment labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "tcO5Pok-0mSa"
   },
   "outputs": [],
   "source": [
    "# 2. Split Data:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "T5qtjXkl0qhT"
   },
   "outputs": [],
   "source": [
    "# 3. Feature Extraction (TF-IDF):\n",
    "vectorizer = TfidfVectorizer(max_features=5000)  # Adjust max_features as needed\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "Nb1i-CTC0uFL",
    "outputId": "cb78920f-90d3-4111-ce60-ad5cb6214ecd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\COMTECH\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Train Model (Logistic Regression):\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FE_izCvw0qcL",
    "outputId": "512b7e97-a77d-47bd-f54f-ce6612747842"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7516778523489933\n"
     ]
    }
   ],
   "source": [
    "# 5. Predict and Evaluate:\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "hlix3itd0qY5"
   },
   "outputs": [],
   "source": [
    "# Function to predict sentiment of input text:\n",
    "def predict_sentiment(input_text):\n",
    "    input_text_tfidf = vectorizer.transform([input_text])\n",
    "    prediction = model.predict(input_text_tfidf)[0]\n",
    "\n",
    "    if prediction == 0:  # Assuming 'negative' is encoded as 0\n",
    "        return \"negative\"\n",
    "    elif prediction == 1: # Assuming 'neutral' is encoded as 1\n",
    "        return \"neutral\"\n",
    "    else: # Assuming 'positive' is encoded as 2\n",
    "        return \"positive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "U2vF30lt0qOH"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your text:  hi what is your namee\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment of 'hi what is your namee': neutral\n"
     ]
    }
   ],
   "source": [
    "# Input from the user:\n",
    "user_input = input(\"Enter your text: \")\n",
    "\n",
    "# Predict and print the sentiment:\n",
    "predicted_sentiment = predict_sentiment(user_input)\n",
    "print(f\"Sentiment of '{user_input}': {predicted_sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "QCFOuG8t0p6I"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# ... (Your model training code) ...\n",
    "\n",
    "# Save the model:\n",
    "with open('sentiment_model.pickle', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# Save the vectorizer:\n",
    "with open('vectorizer.pickle', 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R9Bd8j5jBV9U"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
